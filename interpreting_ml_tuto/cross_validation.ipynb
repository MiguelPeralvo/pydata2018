{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\nCross-validation: some gotchas\n===============================\n\nCross-validation is the ubiquitous test of a machine learning model. Yet\nmany things can go wrong.\n\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "The uncertainty of measured accuracy\n------------------------------------\n\nThe first thing to have in mind is that the results of a\ncross-validation are noisy estimate of the real prediction accuracy\n\nLet us create a simple artificial data\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn import datasets, discriminant_analysis\nimport numpy as np\nnp.random.seed(0)\ndata, target = datasets.make_blobs(centers=[(0, 0), (0, 1)])\nclassifier = discriminant_analysis.LinearDiscriminantAnalysis()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "One cross-validation gives spread out measures\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn.model_selection import cross_val_score\nprint(cross_val_score(classifier, data, target))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "What if we try different random shuffles of the data?\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn import utils\nfor _ in range(10):\n    data, target = utils.shuffle(data, target)\n    print(cross_val_score(classifier, data, target))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "This should not be surprising: if the lassification rate is p, the\nobserved distribution of correct classifications on a set of size\nfollows a binomial distribution\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from scipy import stats\nn = len(data)\ndistrib = stats.binom(n=n, p=.7)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "We can plot it:\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from matplotlib import pyplot as plt\nplt.figure(figsize=(6, 3))\nplt.plot(np.linspace(0, 1, n), distrib.pmf(np.arange(0, n)))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "It is wide, because there are not that many samples to mesure the error\nupon: iris is a small dataset\n\nWe can look at the interval in which 95% of the observed accuracy lies\nfor different sample sizes\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "for n in [100, 1000, 10000, 100000]:\n    distrib = stats.binom(n, .7)\n    interval = (distrib.isf(.025) - distrib.isf(.975)) / n\n    print(\"Size: {0: 7}  | interval: {1}%\".format(n, 100 * interval))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "At 100 000 samples, 5% of the observed classification accuracy still\nfall more than .5% away of the true rate\n\n**Keep in mind that cross-val is a noisy measure**\n\nImportantly, the variance across folds is not a good measure of this\nerror, as the different data folds are not independent. For instance,\ndoing many random splits will can reduce the variance arbitrarily, but\ndoes not provide actually new data points\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Confounding effects and non independence\n-----------------------------------------\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "Measuring baselines and chance\n-------------------------------\n\nBecause of class imbalances, or confounding effects, it is easy to get\nit wrong it terms of what constitutes chances. There are two approaches\nto measure peformances of baselines or chance:\n\n**DummyClassifier** The dummy classifier:\n:class:`sklearn.dummy.DummyClassifier`, with different strategies to\nprovide simple baselines\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn.dummy import DummyClassifier\ndummy = DummyClassifier(strategy=\"stratified\")\nprint(cross_val_score(dummy, data, target))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "**Chance level** To measure actual chance, the most robust approach is\nto use permutations:\n:func:`sklearn.model_selection.permutation_test_score`, which is used\nas cross_val_score\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "from sklearn.model_selection import permutation_test_score\nscore, permuted_scores, p_value = permutation_test_score(classifier, data, target)\nprint(\"Classifier score: {0},\\np value: {1}\\nPermutation scores {2}\"\n        .format(score, p_value, permuted_scores))"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.14", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}